{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Platform: Windows-10-10.0.22621-SP0\n",
      "Tensor Flow Version: 2.10.0\n",
      "Keras Version: 2.10.0\n",
      "\n",
      "Python 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]\n",
      "Pandas 1.5.1\n",
      "Scikit-Learn 1.1.3\n",
      "SciPy 1.9.3\n",
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import tensorflow.keras\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "import scipy as sp\n",
    "import tensorflow as tf\n",
    "import platform\n",
    "import pathlib\n",
    "import random\n",
    "from tensorflow import keras\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import seaborn as sns\n",
    "print(f\"Python Platform: {platform.platform()}\")\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print(f\"Keras Version: {tensorflow.keras.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "print(f\"Pandas {pd.__version__}\")\n",
    "print(f\"Scikit-Learn {sk.__version__}\")\n",
    "print(f\"SciPy {sp.__version__}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables and params\n",
    "#Max batch size= available GPU memory bytes / 4 / (size of tensors + trainable parameters)\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCH = 40\n",
    "BUFFER_SIZE = 2048*2#math.ceil( (8*1024*1024*1024*5)/(256*256*3*8) )#how many images in 5GB of VRAM\n",
    "\n",
    "train_root = pathlib.Path('../../FruitScale/dataextended/Training')\n",
    "train_root = train_root.resolve()\n",
    "\n",
    "test_root = pathlib.Path('../../FruitScale/dataextended/Test')\n",
    "test_root = test_root.resolve()\n",
    "\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful functions\n",
    "def create_image_tensor(image):\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    grayscale = tf.image.rgb_to_grayscale(image)\n",
    "    hsv = tf.image.rgb_to_hsv(image)\n",
    "    res = tf.concat([hsv, grayscale], 2)\n",
    "    #res = image\n",
    "    return res\n",
    "\n",
    "def augment(image):\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.random_hue(image, 0.02)\n",
    "    image = tf.image.random_hue(image, 0.02)\n",
    "    image = tf.image.random_saturation(image, 0.9, 1.2)\n",
    "    image = tf.image.random_flip_left_right(image)\n",
    "    image = tf.image.random_flip_up_down(image)\n",
    "    return create_image_tensor(image)\n",
    "\n",
    "def load_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.rgb_to_hsv(image)\n",
    "    #image = tf.image.decode_jpeg(image, channels=3)\n",
    "    #image = tf.image.resize(image, [256, 256])\n",
    "    return image\n",
    "    #return augment(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of train labels: 131\n",
      "total training count: 354080\n",
      "['Pomelo Sweetie', 'Cherry Wax Red', 'Tamarillo', 'Beetroot', 'Mandarine', 'Grape Blue', 'Apple Golden 1', 'Grape White 4', 'Kiwi', 'Mangostan', 'Rambutan', 'Corn Husk', 'Lemon Meyer', 'Pear Williams', 'Blueberry', 'Cherry Rainier', 'Tomato 4', 'Pear Kaiser', 'Cactus fruit', 'Pepper Orange', 'Guava', 'Kaki', 'Potato White', 'Apple Red Yellow 2', 'Physalis with Husk', 'Watermelon', 'Walnut', 'Salak', 'Tomato 1', 'Plum 2', 'Hazelnut', 'Pepino', 'Apple Red 1', 'Grapefruit Pink', 'Peach', 'Apple Pink Lady', 'Apple Red 3', 'Pineapple', 'Peach 2', 'Pear', 'Pepper Yellow', 'Onion White', 'Pear Red', 'Corn', 'Pear Abate', 'Strawberry Wedge', 'Banana', 'Cherry Wax Yellow', 'Apple Golden 3', 'Tomato Heart', 'Strawberry', 'Apple Red Yellow 1', 'Apple Red Delicious', 'Granadilla', 'Cocos', 'Avocado', 'Tomato not Ripened', 'Pear Monster', 'Peach Flat', 'Physalis', 'Banana Lady Finger', 'Mango Red', 'Limes', 'Dates', 'Potato Sweet', 'Tangelo', 'Cherry 1', 'Potato Red Washed', 'Pear 2', 'Apple Granny Smith', 'Tomato 3', 'Huckleberry', 'Pepper Green', 'Plum', 'Grape White', 'Mulberry', 'Nut Pecan', 'Clementine', 'Carambula', 'Potato Red', 'Melon Piel de Sapo', 'Nectarine Flat', 'Cantaloupe 1', 'Grapefruit White', 'Tomato Cherry Red', 'Cherry 2', 'Nectarine', 'Onion Red', 'Grape White 2', 'Apple Crimson Snow', 'Papaya', 'Maracuja', 'Pitahaya Red', 'Cherry Wax Black', 'Tomato Maroon', 'Pomegranate', 'Apple Red 2', 'Redcurrant', 'Kohlrabi', 'Pear Stone', 'Grape White 3', 'Cantaloupe 2', 'Cauliflower', 'Tomato 2', 'Quince', 'Apricot', 'Fig', 'Passion Fruit', 'Eggplant', 'Ginger Root', 'Tomato Yellow', 'Lemon', 'Nut Forest', 'Pepper Red', 'Plum 3', 'Apple Golden 2', 'Lychee', 'Kumquats', 'Mango', 'Apple Braeburn', 'Avocado ripe', 'Cucumber Ripe', 'Onion Red Peeled', 'Pear Forelle', 'Pineapple Mini', 'Raspberry', 'Chestnut', 'Grape Pink', 'Banana Red', 'Orange', 'Cucumber Ripe 2']\n",
      "Number of validation labels: 131\n",
      "total validation count: 88520\n",
      "Number of test labels: 131\n",
      "total test count: 22688\n"
     ]
    }
   ],
   "source": [
    "# Setting labels and image paths\n",
    "all_image_paths = list(train_root.glob('*/*'))\n",
    "all_image_paths_test = list(test_root.glob('*/*'))\n",
    "random.shuffle(all_image_paths)\n",
    "random.shuffle(all_image_paths_test)\n",
    "#print(all_image_paths[10])\n",
    "\n",
    "total_image_count = len(all_image_paths)\n",
    "total_image_count_test = len(all_image_paths_test)\n",
    "\n",
    "validation_count = math.ceil(total_image_count * 0.20)\n",
    "training_count = total_image_count - validation_count\n",
    "\n",
    "# Training images\n",
    "train_labels = [str(path.parent.name) for path in all_image_paths[0: training_count]]\n",
    "train_image_path = [str(path) for path in all_image_paths[0: training_count]]\n",
    "train_labels = list(dict.fromkeys(train_labels))\n",
    "print(\"Number of train labels: \" + str(len(train_labels)))\n",
    "print(\"total training count: \" + str(len(train_image_path)))\n",
    "print(train_labels)\n",
    "\n",
    "# Validation images\n",
    "validation_labels = [str(path.parent.name) for path in all_image_paths[training_count:]]\n",
    "validation_image_path = [str(path) for path in all_image_paths[training_count:]]\n",
    "validation_labels = list(dict.fromkeys(validation_labels))\n",
    "print(\"Number of validation labels: \" + str(len(validation_labels)))\n",
    "print(\"total validation count: \" + str(len(validation_image_path)))\n",
    "\n",
    "# Test images\n",
    "test_labels = [str(path.parent.name) for path in all_image_paths_test]\n",
    "test_image_path = [str(path) for path in all_image_paths_test]\n",
    "test_labels = list(dict.fromkeys(test_labels))\n",
    "print(\"Number of test labels: \" + str(len(test_labels)))\n",
    "print(\"total test count: \" + str(len(test_image_path)))\n",
    "\n",
    "#Generating index\n",
    "label_to_index = dict((name, index) for index, name in enumerate(train_labels))\n",
    "#print(label_to_index)\n",
    "\n",
    "train_labels = [label_to_index[pathlib.Path(path).parent.name]\n",
    "                for path in train_image_path]\n",
    "\n",
    "validation_labels = [label_to_index[pathlib.Path(path).parent.name]\n",
    "                     for path in validation_image_path]\n",
    "\n",
    "test_labels = [label_to_index[pathlib.Path(path).parent.name]\n",
    "               for path in test_image_path]\n",
    "\n",
    "#print(len(train_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the training data set\n",
    "train_path_ds = tf.data.Dataset.from_tensor_slices(train_image_path)\n",
    "train_image_ds = train_path_ds.map(load_image, tf.data.AUTOTUNE)\n",
    "train_label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(train_labels, tf.uint8))\n",
    "\n",
    "train_data = tf.data.Dataset.zip((train_image_ds, train_label_ds))\n",
    "\n",
    "#ds = data.apply(tf.data.Dataset.shuffle(buffer_size=100000))\n",
    "\n",
    "train_ds = train_data.shuffle(buffer_size=math.ceil(BUFFER_SIZE))\n",
    "train_ds = train_ds.batch(BATCH_SIZE)\n",
    "\n",
    "train_ds = train_ds.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Generating the validation dataset\n",
    "validation_path_ds = tf.data.Dataset.from_tensor_slices(validation_image_path)\n",
    "validation_image_ds = validation_path_ds.map(load_image, tf.data.AUTOTUNE)\n",
    "validation_label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(validation_labels, tf.uint8))\n",
    "\n",
    "validation_data = tf.data.Dataset.zip((validation_image_ds, validation_label_ds))\n",
    "\n",
    "#ds = data.apply(tf.data.Dataset.shuffle(buffer_size=100000))\n",
    "\n",
    "validation_ds = validation_data.shuffle(buffer_size=math.ceil(BUFFER_SIZE))\n",
    "validation_ds = validation_ds.batch(BATCH_SIZE)\n",
    "\n",
    "validation_ds = validation_ds.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22688\n",
      "22688\n"
     ]
    }
   ],
   "source": [
    "# Generating the test dataset\n",
    "test_path_ds = tf.data.Dataset.from_tensor_slices(test_image_path)\n",
    "test_image_ds = test_path_ds.map(load_image, tf.data.AUTOTUNE)\n",
    "test_label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(test_labels, tf.uint8))\n",
    "\n",
    "print(len(test_image_ds))\n",
    "print(len(test_label_ds))\n",
    "\n",
    "test_data = tf.data.Dataset.zip((test_image_ds, test_label_ds))\n",
    "\n",
    "#ds = data.apply(tf.data.Dataset.shuffle(buffer_size=100000))\n",
    "\n",
    "test_ds = test_data.shuffle(buffer_size=math.ceil(total_image_count_test))\n",
    "test_ds = test_ds.batch(BATCH_SIZE)\n",
    "\n",
    "test_ds = test_ds.prefetch(buffer_size=tf.data.AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using `weights` as `\"imagenet\"` with `include_top` as true, `classes` should be 1000. Received `classes=131`",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [8], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m base_model\u001B[38;5;241m=\u001B[39m\u001B[43mtf\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mkeras\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mapplications\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmobilenet_v2\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mMobileNetV2\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_shape\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m100\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;66;43;03m#include_top=False,\u001B[39;49;00m\n\u001B[0;32m      4\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclasses\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m131\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m    \u001B[49m\u001B[43mweights\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mimagenet\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\n\u001B[0;32m      6\u001B[0m \u001B[43m)\u001B[49m\n\u001B[0;32m      7\u001B[0m base_model\u001B[38;5;241m.\u001B[39msummary()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\applications\\mobilenet_v2.py:211\u001B[0m, in \u001B[0;36mMobileNetV2\u001B[1;34m(input_shape, alpha, include_top, weights, input_tensor, pooling, classes, classifier_activation, **kwargs)\u001B[0m\n\u001B[0;32m    202\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    203\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe `weights` argument should be either \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    204\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m`None` (random initialization), `imagenet` \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    207\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReceived `weights=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mweights\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    208\u001B[0m     )\n\u001B[0;32m    210\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m weights \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimagenet\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m include_top \u001B[38;5;129;01mand\u001B[39;00m classes \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m1000\u001B[39m:\n\u001B[1;32m--> 211\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    212\u001B[0m         \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mIf using `weights` as `\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mimagenet\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m` with `include_top` \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m    213\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas true, `classes` should be 1000. Received `classes=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mclasses\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m`\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    214\u001B[0m     )\n\u001B[0;32m    216\u001B[0m \u001B[38;5;66;03m# Determine proper input shape and default size.\u001B[39;00m\n\u001B[0;32m    217\u001B[0m \u001B[38;5;66;03m# If both input_shape and input_tensor are used, they should match\u001B[39;00m\n\u001B[0;32m    218\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m input_shape \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m input_tensor \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mValueError\u001B[0m: If using `weights` as `\"imagenet\"` with `include_top` as true, `classes` should be 1000. Received `classes=131`"
     ]
    }
   ],
   "source": [
    "base_model=tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
    "    input_shape=(100,100,3),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\"\n",
    ")\n",
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
    "dropout = tf.keras.layers.Dropout(0.2)\n",
    "prediction_layer = tf.keras.layers.Dense(131, activation= 'softmax')\n",
    "inputs = tf.keras.Input(shape=(100, 100, 3))\n",
    "#x = preprocess_input(inputs)\n",
    "x = base_model(inputs)\n",
    "x = global_average_layer(x)\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "outputs = prediction_layer(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "early_stop = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    verbose=1,\n",
    "    patience=5,\n",
    "    restore_best_weights=True,)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=NUM_EPOCH,\n",
    "    validation_data=validation_ds,\n",
    "    verbose=1,\n",
    "    callbacks=[early_stop],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.save(\"trained_mobilenet_HSV_with_dropout_from_scratch.h5\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc, *is_anything_else_being_returned = model.evaluate(test_ds)\n",
    "print('Loss:', loss)\n",
    "print('Accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='lower right')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper right')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "y_pred = []  # store predicted labels\n",
    "y_true = []  # store true labels\n",
    "\n",
    "# iterate over the dataset\n",
    "for image_batch, label_batch in test_ds:   # use dataset.unbatch() with repeat\n",
    "    # append true labels\n",
    "    y_true.append(label_batch)\n",
    "    # compute predictions\n",
    "    preds = model.predict(image_batch)\n",
    "    # append predicted labels\n",
    "    y_pred.append(np.argmax(preds, axis = - 1))\n",
    "\n",
    "# convert the true and predicted labels into tensors\n",
    "correct_labels = tf.concat([item for item in y_true], axis = 0)\n",
    "predicted_labels = tf.concat([item for item in y_pred], axis = 0)\n",
    "\n",
    "print(confusion_matrix(y_true=correct_labels, y_pred=predicted_labels))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(classification_report(correct_labels,predicted_labels))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "cf_matrix = confusion_matrix(y_true=correct_labels, y_pred=predicted_labels)\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "sns.heatmap(cf_matrix, ax=ax,)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "index = label_to_index#list(label_to_index.keys())\n",
    "def getPredictionClass(predictions):\n",
    "    i=0\n",
    "    for prediction in predictions:\n",
    "        if prediction > 0.0:\n",
    "            k = 0\n",
    "            for a,b in index.items():\n",
    "                if k == i:\n",
    "                    print(a + \": \" + str(prediction))\n",
    "                k = k + 1\n",
    "        i = i+1"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "x = random.choice(os.listdir(str(test_root) + '/Apple Red 3'))\n",
    "print(x)\n",
    "img = plt.imread(os.path.join(str(test_root) + '/Apple Red 3', x))\n",
    "img = cv2.resize(img, dsize=(256, 256))\n",
    "img = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "#img_new = keras.applications.mobilenet.preprocess_input(img)\n",
    "plt.imshow(img)\n",
    "img = img/256\n",
    "#print(img.shape)\n",
    "#print((np.expand_dims(img,0).shape))\n",
    "\n",
    "predictions = model.predict(np.expand_dims(img,0)).round(2)[0]\n",
    "#print(predictions)\n",
    "getPredictionClass(predictions)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
